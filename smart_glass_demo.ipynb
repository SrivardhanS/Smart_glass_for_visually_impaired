{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5553ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pyautogui\n",
    "import time\n",
    "from math import hypot\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from directkeys import PressKey, ReleaseKey,W,A,S,D\n",
    "import pydirectinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7574a721",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "pose_image = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5,model_complexity=1)\n",
    "\n",
    "pose_video = mp_pose.Pose(static_image_mode=False, model_complexity=1 ,min_tracking_confidence=0.7)\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "141774b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectPose(image, pose, draw = False, display =False):\n",
    "\n",
    "    output_image = image.copy()\n",
    "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(imageRGB)\n",
    "\n",
    "    if results.pose_landmarks and draw:\n",
    "        mp_drawing.draw_landmarks(image = output_image, landmark_list = results.pose_landmarks, connections = mp_pose.POSE_CONNECTIONS,\n",
    "                                 landmark_drawing_spec=mp_drawing.DrawingSpec(color = (255,255,255),thickness =3, circle_radius =3),\n",
    "                                 connection_drawing_spec = mp_drawing.DrawingSpec(color = (49,125,237),thickness =2, circle_radius = 2))\n",
    "\n",
    "    if display:\n",
    "        plt.figure(figsize = [22,22])\n",
    "        plt.subplot(121);plt.imshow(image[:,:,::-1]);plt.title(\"Original Image\");plt.axis('off');\n",
    "        plt.subplot(122);plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "    else:\n",
    "        return output_image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90cdd244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAccDec(image , results , draw = False , display = False):\n",
    "    \n",
    "    \n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    # Create a copy of the input image to write the hands status label on.\n",
    "    output_image = image.copy()\n",
    "    \n",
    "    left_line = (width//2) -190\n",
    "    right_line = (width//2)  + 190\n",
    "    \n",
    "    \n",
    "    height_right_wrist = int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST].y * height)\n",
    "    \n",
    "    if(height_right_wrist<450):\n",
    "        posture=\"ACCELERATE\"\n",
    "    elif(height_right_wrist>450 and height_right_wrist<720):\n",
    "        posture=\"DECELERATE\"\n",
    "    else:\n",
    "        posture=\"NIL\"\n",
    "    \n",
    "    if draw:\n",
    "        cv2.putText(output_image, posture , (5, height - 50), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 3)\n",
    "        cv2.line(output_image, (left_line,0),(left_line,height),(255, 255, 255), 2)\n",
    "        cv2.line(output_image, (right_line,0),(right_line,height),(255, 255, 255), 2)\n",
    "        cv2.line(output_image, (0, 450),(width, 450),(255, 255, 255), 2)\n",
    "    \n",
    "    if display:\n",
    "\n",
    "        # Display the output image.\n",
    "        plt.figure(figsize=[10,10])\n",
    "        plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "    \n",
    "    # Otherwise\n",
    "    else:\n",
    "    \n",
    "        # Return the output image and posture indicating whether the person is standing straight or has jumped, or crouched.\n",
    "        return output_image, posture\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c1ad48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera_video = cv2.VideoCapture(0)\n",
    "# camera_video.set(3,1280)\n",
    "# camera_video.set(4,960)\n",
    " \n",
    "# # Create named window for resizing purposes.\n",
    "# cv2.namedWindow('Verticial Movements', cv2.WINDOW_NORMAL)\n",
    " \n",
    "# # Iterate until the webcam is accessed successfully.\n",
    "# while camera_video.isOpened():\n",
    "    \n",
    "#     # Read a frame.\n",
    "#     ok, frame = camera_video.read()\n",
    "    \n",
    "#     # Check if frame is not read properly then continue to the next iteration to read the next frame.\n",
    "#     if not ok:\n",
    "#         continue\n",
    "    \n",
    "#     # Flip the frame horizontally for natural (selfie-view) visualization.\n",
    "#     frame = cv2.flip(frame, 1)\n",
    "    \n",
    "#     # Get the height and width of the frame of the webcam video.\n",
    "#     frame_height, frame_width, _ = frame.shape\n",
    "    \n",
    "#     # Perform the pose detection on the frame.\n",
    "#     frame, results = detectPose(frame, pose_video, draw=True)\n",
    "    \n",
    "#     # Check if the pose landmarks in the frame are detected.\n",
    "#     if results.pose_landmarks:\n",
    "            \n",
    "#         # Check the posture (jumping, crouching or standing) of the person in the frame. \n",
    "#         frame, _ = checkAccDec(frame, results, draw=True)\n",
    "                \n",
    "#     # Display the frame.\n",
    "#     cv2.imshow('ACC OR DEC', frame)\n",
    "    \n",
    "#     # Wait for 1ms. If a a key is pressed, retreive the ASCII code of the key.\n",
    "#     k = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "#     # Check if 'ESC' is pressed and break the loop.\n",
    "#     if(k == 27):\n",
    "#         break\n",
    " \n",
    "# # Release the VideoCapture Object and close the windows.\n",
    "# camera_video.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3717ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkLeftRight(image, results, draw = False, display = False):\n",
    "    \n",
    "    # Get the height and width of the image.\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    # Create a copy of the input image to write the horizontal position on.\n",
    "    output_image = image.copy()\n",
    "    \n",
    "    posture = \"posture\"\n",
    "    \n",
    "    left_x = int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * width)\n",
    " \n",
    "    right_x = int(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * width)\n",
    "    \n",
    "    \n",
    "    \n",
    "    center = (left_x+right_x)//2\n",
    "    \n",
    "    left_line = (width//2) -190\n",
    "    right_line = (width//2)  + 190\n",
    "    #left_line_extreme = (width//2) -230\n",
    "    #right_line_extreme = (width//2)  + 230\n",
    "    \n",
    "    if left_x <= left_line:\n",
    "        posture = \"Left\"\n",
    "    elif right_x >= right_line:\n",
    "        posture = \"Right\"\n",
    "    else:\n",
    "        posture = \"Normal Front\"\n",
    "            \n",
    "    if draw:\n",
    "        cv2.putText(output_image, posture, (5, height - 50), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 3)\n",
    "        cv2.line(output_image, (center,0),(center,height),(255, 255, 255), 2)\n",
    "        cv2.line(output_image, (left_line,0),(left_line,height),(255, 255, 255), 2)\n",
    "        cv2.line(output_image, (right_line,0),(right_line,height),(255, 255, 255), 2)\n",
    "        #cv2.line(output_image, (left_line_extreme,0),(left_line_extreme,height),(255, 255, 255), 2)\n",
    "        #cv2.line(output_image, (right_line_extreme,0),(right_line_extreme,height),(255, 255, 255), 2)\n",
    "          \n",
    "        \n",
    "    if display:\n",
    "        plt.figure(figsize= [10,10])\n",
    "        \n",
    "        plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "        plt.show() # added this line to plot\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return output_image, posture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "408dbac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera_video = cv2.VideoCapture(0)\n",
    "# camera_video.set(3,1280)\n",
    "# camera_video.set(4,960)\n",
    " \n",
    "# # Create named window for resizing purposes.\n",
    "# cv2.namedWindow('lr Movements', cv2.WINDOW_NORMAL)\n",
    " \n",
    "# # Iterate until the webcam is accessed successfully.\n",
    "# while camera_video.isOpened():\n",
    "    \n",
    "#     # Read a frame.\n",
    "#     ok, frame = camera_video.read()\n",
    "    \n",
    "#     # Check if frame is not read properly then continue to the >next iteration to read the next frame.\n",
    "#     if not ok:\n",
    "#         continue\n",
    "    \n",
    "#     # Flip the frame horizontally for natural (selfie-view) visualization.\n",
    "#     frame = cv2.flip(frame, 1)\n",
    "    \n",
    "#     # Get the height and width of the frame of the webcam video.\n",
    "#     frame_height, frame_width, _ = frame.shape\n",
    "    \n",
    "#     # Perform the pose detection on the frame.\n",
    "#     frame, results = detectPose(frame, pose_video, draw=True)\n",
    "    \n",
    "#     # Check if the pose landmarks in the frame are detected.\n",
    "#     if results.pose_landmarks:\n",
    "            \n",
    "#         # Check the posture (jumping, crouching or standing) of the person in the frame. \n",
    "#         frame, _ = checkLeftRight(frame, results, draw=True)\n",
    "                \n",
    "#     # Display the frame.\n",
    "#     cv2.imshow('LEFT OR RIGHT', frame)\n",
    "    \n",
    "#     # Wait for 1ms. If a a key is pressed, retreive the ASCII code of the key.\n",
    "#     k = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "#     # Check if 'ESC' is pressed and break the loop.\n",
    "#     if(k == 27):\n",
    "#         break\n",
    " \n",
    "# # Release the VideoCapture Object and close the windows.\n",
    "# camera_video.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62bb55a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkHandsJoined(image, results, draw=False, display=False):\n",
    "    '''\n",
    "    This function checks whether the hands of the person are joined or not in an image.\n",
    "    Args:\n",
    "        image:   The input image with a prominent person whose hands status (joined or not) needs to be classified.\n",
    "        results: The output of the pose landmarks detection on the input image.\n",
    "        draw:    A boolean value that is if set to true the function writes the hands status &amp; distance on the output image. \n",
    "        display: A boolean value that is if set to true the function displays the resultant image and returns nothing.\n",
    "    Returns:\n",
    "        output_image: The same input image but with the classified hands status written, if it was specified.\n",
    "        hand_status:  The classified status of the hands whether they are joined or not.\n",
    "    '''\n",
    "    \n",
    "    # Get the height and width of the input image.\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    # Create a copy of the input image to write the hands status label on.\n",
    "    output_image = image.copy()\n",
    "    \n",
    "    # Get the left wrist landmark x and y coordinates.\n",
    "    left_wrist_landmark = (results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST].x * width,\n",
    "                          results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST].y * height)\n",
    " \n",
    "    # Get the right wrist landmark x and y coordinates.\n",
    "    right_wrist_landmark = (results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST].x * width,\n",
    "                           results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST].y * height)\n",
    "    \n",
    "    # Calculate the euclidean distance between the left and right wrist.\n",
    "    euclidean_distance = int(hypot(left_wrist_landmark[0] - right_wrist_landmark[0],\n",
    "                                   left_wrist_landmark[1] - right_wrist_landmark[1]))\n",
    "    \n",
    "    # Compare the distance between the wrists with a appropriate threshold to check if both hands are joined.\n",
    "    if euclidean_distance<130:\n",
    "        \n",
    "        # Set the hands status to joined.\n",
    "        hand_status = 'Hands Joined'\n",
    "        \n",
    "        # Set the color value to green.\n",
    "        color = (0, 255, 0)\n",
    "        \n",
    "    # Otherwise.    \n",
    "    else:\n",
    "        \n",
    "        # Set the hands status to not joined.\n",
    "        hand_status = 'Hands Not Joined'\n",
    "        \n",
    "        # Set the color value to red.\n",
    "        color = (0, 0, 255)\n",
    "        \n",
    "    # Check if the Hands Joined status and hands distance are specified to be written on the output image.\n",
    "    if draw:\n",
    " \n",
    "        # Write the classified hands status on the image. \n",
    "        cv2.putText(output_image, hand_status, (10, 30), cv2.FONT_HERSHEY_PLAIN, 2, color, 3)\n",
    "        \n",
    "        # Write the the distance between the wrists on the image. \n",
    "        cv2.putText(output_image, f'Distance: {euclidean_distance}', (10, 70),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 2, color, 3)\n",
    "        \n",
    "    # Check if the output image is specified to be displayed.\n",
    "    if display:\n",
    " \n",
    "        # Display the output image.\n",
    "        plt.figure(figsize=[10,10])\n",
    "        plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "    \n",
    "    # Otherwise\n",
    "    else:\n",
    "    \n",
    "        # Return the output image and the classified hands status indicating whether the hands are joined or not.\n",
    "        return output_image, hand_status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a035efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera_video = cv2.VideoCapture(0)\n",
    "# camera_video.set(3,1280)\n",
    "# camera_video.set(4,960)\n",
    " \n",
    "# # Create named window for resizing purposes.\n",
    "# cv2.namedWindow('Asphalt 9 Pose Detection', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# # Initialize a variable to store the time of the previous frame.\n",
    "# time1 = 0\n",
    "\n",
    "# # Initialize a variable to store the state of the game (started or not).\n",
    "# game_started = False  \n",
    "\n",
    "\n",
    "# num_of_frames = 10\n",
    "\n",
    "# #currentKey = list()\n",
    "\n",
    "# last_left_press_time = time.time()\n",
    "# last_right_press_time = time.time()\n",
    "\n",
    "# while camera_video.isOpened():\n",
    "    \n",
    "#     # Read a frame.\n",
    "#     ok, frame = camera_video.read()\n",
    "#     ok, frame1 = camera_video.read()\n",
    "    \n",
    "#     # Check if frame is not read properly then continue to the next iteration to read the next frame.\n",
    "#     if not ok:\n",
    "#         continue\n",
    "        \n",
    "#     frame = cv2.flip(frame, 1)\n",
    "#     frame1 = cv2.flip(frame1,1)\n",
    "    \n",
    "#     # Get the height and width of the frame of the webcam video.\n",
    "#     frame_height, frame_width, _ = frame.shape\n",
    "    \n",
    "#     # Perform the pose detection on the frame.\n",
    "#     frame, results = detectPose(frame, pose_video, draw=game_started)\n",
    "#     frame1, results = detectPose(frame1, pose_video,draw=False)\n",
    "    \n",
    "#     key=False\n",
    "        \n",
    "#     if results.pose_landmarks:\n",
    "        \n",
    "#         # Check if the game has started\n",
    "#         if game_started:\n",
    "            \n",
    "            \n",
    "#             frame, accordec = checkAccDec(frame, results, draw=True)\n",
    "#             frame1 ,lor = checkLeftRight(frame1, results, draw = False)\n",
    "#             #key = False\n",
    "\n",
    "        \n",
    "#             if accordec == \"ACCELERATE\":\n",
    "#                 PressKey(W)\n",
    "#             else:\n",
    "#                 ReleaseKey(W)\n",
    "\n",
    "#             if accordec == \"DECELERATE\":\n",
    "#                 PressKey(S)\n",
    "#             else:\n",
    "#                 ReleaseKey(S)\n",
    "\n",
    "        \n",
    "#             if lor == \"Left\" and (time.time() - last_left_press_time) >= 0.5:\n",
    "#                 PressKey(A)\n",
    "#                 last_left_press_time = time.time()\n",
    "           \n",
    "\n",
    "#             if lor == \"Right\" and (time.time() - last_right_press_time) >= 0.5:\n",
    "#                 PressKey(D)\n",
    "#                 last_right_press_time = time.time()\n",
    "             \n",
    "                 \n",
    "#         else:\n",
    "            \n",
    "#             # Write the text representing the way to start the game on the frame. \n",
    "#             cv2.putText(frame, 'JOIN BOTH HANDS TO START THE GAME.', (5, frame_height - 10), cv2.FONT_HERSHEY_PLAIN,\n",
    "#                         2, (0, 255, 0), 3)\n",
    "        \n",
    "      \n",
    "#         if checkHandsJoined(frame, results)[1] == 'Hands Joined':\n",
    "#             counter += 1\n",
    "#              #counter is used to give the base time after which the detection should be started \n",
    "#             # Check if the counter is equal to the required number of consecutive frames.  \n",
    "    \n",
    "#             if counter == num_of_frames:\n",
    "                \n",
    "#                 # Command to Start the game first time.\n",
    "#                 #----------------------------------------------------------------------------------------------------------\n",
    "#                 # Check if the game has not started yet.\n",
    "#                 if not(game_started):\n",
    "#                     counter=0\n",
    "#                     # Update the value of the variable that stores the game state.\n",
    "#                     game_started = True\n",
    "#                     pyautogui.press(keys='enter', presses=2)\n",
    "#                 else:\n",
    "#                     counter=0\n",
    "#                     #pyautogui.press()\n",
    "#                     game_started = False\n",
    "#         else:\n",
    "#             counter=0\n",
    "            \n",
    "#         time2 = time.time()\n",
    "    \n",
    "#         # Check if the difference between the previous and this frame time &gt; 0 to avoid division by zero.\n",
    "#         if (time2 - time1) > 0:\n",
    "    \n",
    "#         # Calculate the number of frames per second.\n",
    "#             frames_per_second = 1.0 / (time2 - time1)\n",
    "        \n",
    "#         # Write the calculated number of frames per second on the frame.\n",
    "#             cv2.putText(frame, 'FPS: {}'.format(int(frames_per_second)), (10, 30),cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 3)\n",
    "    \n",
    "#     # Update the previous frame time to this frame time.\n",
    "#     # As this frame will become previous frame in next iteration.\n",
    "#         time1 = time2\n",
    "    \n",
    "#     #----------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "#     # Display the frame.            \n",
    "#         cv2.imshow('Asphalt 9 Pose Detection', frame)\n",
    "        \n",
    "        \n",
    "#         #if not key and len(currentKey) != 0:\n",
    "#           #  for current in currentKey:\n",
    "#           #      ReleaseKey(current)\n",
    "#          #   currentKey = list()\n",
    "\n",
    "    \n",
    "#     # Wait for 1ms. If a a key is pressed, retreive the ASCII code of the key.\n",
    "#         k = cv2.waitKey(1) & 0xFF    \n",
    "    \n",
    "#     # Check if 'ESC' is pressed and break the loop.\n",
    "#         if(k == 27):\n",
    "#             break\n",
    " \n",
    "# # Release the VideoCapture Object and close the windows.                  \n",
    "# camera_video.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65404dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_video = cv2.VideoCapture(0)\n",
    "camera_video.set(3, 1280)\n",
    "camera_video.set(4, 960)\n",
    "\n",
    "cv2.namedWindow('Asphalt 9 Pose Detection', cv2.WINDOW_NORMAL)\n",
    "\n",
    "time1 = 0\n",
    "game_started = False\n",
    "\n",
    "num_of_frames = 10\n",
    "counter = 0\n",
    "\n",
    "last_left_press_time = time.time()\n",
    "last_right_press_time = time.time()\n",
    "\n",
    "while camera_video.isOpened():\n",
    "    ok, frame = camera_video.read()\n",
    "    ok, frame1 = camera_video.read()\n",
    "\n",
    "    if not ok:\n",
    "        continue\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame1 = cv2.flip(frame1, 1)\n",
    "\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "    frame, results = detectPose(frame, pose_video, draw=game_started)\n",
    "    frame1, results = detectPose(frame1, pose_video, draw=False)\n",
    "\n",
    "    key = False\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "\n",
    "        if game_started:\n",
    "\n",
    "            frame, accordec = checkAccDec(frame, results, draw=True)\n",
    "            frame1, lor = checkLeftRight(frame1, results, draw=False)\n",
    "\n",
    "            if accordec == \"ACCELERATE\":\n",
    "                PressKey(W)\n",
    "            else:\n",
    "                ReleaseKey(W)\n",
    "\n",
    "            if accordec == \"DECELERATE\":\n",
    "                PressKey(S)\n",
    "            else:\n",
    "                ReleaseKey(S)\n",
    "\n",
    "            if lor == \"Left\" and (time.time() - last_left_press_time) >= 0.5:\n",
    "                PressKey(A)\n",
    "                last_left_press_time = time.time()\n",
    "\n",
    "            if lor == \"Right\" and (time.time() - last_right_press_time) >= 0.5:\n",
    "                PressKey(D)\n",
    "                last_right_press_time = time.time()\n",
    "\n",
    "        else:\n",
    "\n",
    "            cv2.putText(frame, 'JOIN BOTH HANDS TO START THE GAME.', (5, frame_height - 10),\n",
    "                        cv2.FONT_HERSHEY_PLAIN,\n",
    "                        2, (0, 255, 0), 3)\n",
    "\n",
    "        if checkHandsJoined(frame, results)[1] == 'Hands Joined':\n",
    "            counter += 1\n",
    "\n",
    "            if counter == num_of_frames:\n",
    "                if not (game_started):\n",
    "                    counter = 0\n",
    "                    game_started = True\n",
    "                    pyautogui.press(keys='enter', presses=2)\n",
    "                else:\n",
    "                    counter = 0\n",
    "                    game_started = False\n",
    "        else:\n",
    "            counter = 0\n",
    "\n",
    "        time2 = time.time()\n",
    "\n",
    "        if (time2 - time1) > 0:\n",
    "            frames_per_second = 1.0 / (time2 - time1)\n",
    "            cv2.putText(frame, 'FPS: {}'.format(int(frames_per_second)), (10, 30),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 3)\n",
    "\n",
    "    time1 = time2\n",
    "\n",
    "    cv2.imshow('Asphalt 9 Pose Detection', frame)\n",
    "\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if (k == 27):\n",
    "        break\n",
    "\n",
    "camera_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb868d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
